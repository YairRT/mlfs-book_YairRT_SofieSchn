{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4447764c-218b-441a-ab97-4df4062960d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    \n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Daily Feature Pipeline for Air Quality (aqicn.org) and weather (openmeteo)</span>\n",
    "\n",
    "## \ud83d\uddd2\ufe0f This notebook is divided into the following sections:\n",
    "1. Download and Parse Data\n",
    "2. Feature Group Insertion\n",
    "\n",
    "\n",
    "__This notebook should be scheduled to run daily__\n",
    "\n",
    "In the book, we use a GitHub Action stored here:\n",
    "[.github/workflows/air-quality-daily.yml](https://github.com/featurestorebook/mlfs-book/blob/main/.github/workflows/air-quality-daily.yml)\n",
    "\n",
    "However, you are free to use any Python Orchestration tool to schedule this program to run daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe638c6",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> \ud83d\udcdd Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "from mlfs import config\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ff6a1",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "country = \"united-kingdomfa\"\n",
    "city = \"scotland\"\n",
    "street = \"edinburgh-salamander-st\"\n",
    "aqicn_url = \"https://api.waqi.info/feed/@5986\"\n",
    "sensor_secret_name = f\"SENSOR_LOCATION_JSON_{street.replace(' ', '_')}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6081d1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> \ud83c\udf0d Get the Sensor URL, Country, City, Street names from Hopsworks </span>\n",
    "\n",
    "__Update the values in the cell below.__\n",
    "\n",
    "__These should be the same values as in notebook 1 - the feature backfill notebook__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project = hopsworks.login(engine=\"python\")\n",
    "fs = project.get_feature_store() \n",
    "secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "# This line will fail if you have not registered the AQICN_API_KEY as a secret in Hopsworks\n",
    "AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "location_str = secrets.get_secret(sensor_secret_name).value\n",
    "location = json.loads(location_str)\n",
    "\n",
    "#country=location['country']\n",
    "#city=location['city']\n",
    "#street=location['street']\n",
    "#aqicn_url=location['aqicn_url']\n",
    "latitude=location['latitude']\n",
    "longitude=location['longitude']\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "location_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf9289",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> \ud83d\udd2e Get references to the Feature Groups </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality',\n",
    "    version=2,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b6ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ffa41",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> \ud83c\udf2b Retrieve Today's Air Quality data (PM2.5) from the AQI API</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f681af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "aq_today_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e24eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_today_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af845ab6",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> \ud83c\udf26 Get Weather Forecast data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecb3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude)\n",
    "hourly_df = hourly_df.set_index('date')\n",
    "\n",
    "# We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "# We only want the daily weather data, so only get weather at 12:00\n",
    "daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "daily_df = daily_df.reset_index()\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "daily_df['city'] = city\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c563109",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c level implementation, read the new lag features from hopswork\n",
    "# Get recent PM2.5 history to compute lag features (last 3 days)\n",
    "# We need to read from the feature group to get historical PM2.5 values\n",
    "recent_days = 3\n",
    "cutoff_date = today - datetime.timedelta(days=recent_days + 1)\n",
    "\n",
    "# Save original aq_today_df with all columns (including url) before processing\n",
    "aq_today_df_original = aq_today_df.copy()\n",
    "\n",
    "# Read recent air quality data for this street\n",
    "recent_aq = air_quality_fg.filter(\n",
    "    (air_quality_fg.street == street) & \n",
    "    (air_quality_fg.date >= cutoff_date)\n",
    ").read()\n",
    "\n",
    "# Sort by date\n",
    "recent_aq = recent_aq.sort_values('date')\n",
    "\n",
    "# Combine recent data with today's data for lag computation\n",
    "# Include url column if it exists in recent_aq, otherwise we'll add it back later\n",
    "cols_to_merge = ['date', 'pm25', 'country', 'city', 'street']\n",
    "if 'url' in recent_aq.columns:\n",
    "    cols_to_merge.append('url')\n",
    "    \n",
    "aq_with_history = pd.concat([recent_aq[cols_to_merge], \n",
    "                             aq_today_df[cols_to_merge]], \n",
    "                            ignore_index=True)\n",
    "aq_with_history = aq_with_history.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# Compute lag features\n",
    "aq_with_history['pm25_lag_1'] = aq_with_history['pm25'].shift(1)\n",
    "aq_with_history['pm25_lag_2'] = aq_with_history['pm25'].shift(2)\n",
    "aq_with_history['pm25_lag_3'] = aq_with_history['pm25'].shift(3)\n",
    "\n",
    "# Compute rolling 3-day mean\n",
    "aq_with_history['pm25_roll_3'] = aq_with_history['pm25'].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "# Extract only today's row with lag features\n",
    "aq_today_df = aq_with_history[aq_with_history['date'] == pd.to_datetime(today)].copy()\n",
    "\n",
    "# Ensure url column is present (add from original if missing)\n",
    "if 'url' not in aq_today_df.columns and 'url' in aq_today_df_original.columns:\n",
    "    aq_today_df['url'] = aq_today_df_original['url'].iloc[0]\n",
    "\n",
    "# Fill NaN values with 0.0 (for the first few days when history is insufficient)\n",
    "aq_today_df[['pm25_lag_1', 'pm25_lag_2', 'pm25_lag_3', 'pm25_roll_3']] = \\\n",
    "    aq_today_df[['pm25_lag_1', 'pm25_lag_2', 'pm25_lag_3', 'pm25_roll_3']].fillna(0.0)\n",
    "\n",
    "# Ensure date is datetime\n",
    "aq_today_df['date'] = pd.to_datetime(aq_today_df['date'])\n",
    "\n",
    "print(\"Today's data with lag features:\")\n",
    "print(aq_today_df[['date', 'pm25', 'pm25_lag_1', 'pm25_lag_2', 'pm25_lag_3', 'pm25_roll_3']])\n",
    "print(f\"\\nColumns in aq_today_df: {aq_today_df.columns.tolist()}\")\n",
    "aq_today_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">\u2b06\ufe0f Uploading new data to the Feature Store</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9de5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert new data\n",
    "air_quality_fg.insert(aq_today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert new data\n",
    "weather_fg.insert(daily_df, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9e2d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">\u23ed\ufe0f **Next:** Part 03: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will read from a feature group and create training dataset within the feature store\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}